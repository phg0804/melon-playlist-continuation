{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm\n",
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from arena_util import remove_seen\n",
    "from arena_util import write_json\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "from gensim.parsing.preprocessing import preprocess_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./data/train.json', encoding='UTF-8')\n",
    "val = pd.read_json('./data/val.json', encoding='UTF-8')\n",
    "song_meta = pd.read_json('./data/song_meta.json', encoding='UTF-8')\n",
    "most_results = pd.read_json('results.json', encoding='UTF-8')\n",
    "min_count = 10\n",
    "size = 100\n",
    "windows = 100\n",
    "sg = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2v_model = WordEmbeddingsKeyedVectors(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas apply 진행상황 보여주기 위한 모듈\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- song_name_dic  \n",
    "    plylst id와 song name을 분해한 list를 매칭(plylst id - \\[song1 분해, song2 분해, ... \\])\n",
    "- total(pandas.Series)  \n",
    "    song name 분해한 것 + tag + plylst 제목 분해한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 138086/138086 [12:16<00:00, 187.38it/s]\n"
     ]
    }
   ],
   "source": [
    "song_dic = {} # plylst id - song id\n",
    "song_name_dic = {} # plylst id - [preprocessed song name]\n",
    "tag_dic = {} # plylst id - tag\n",
    "data = pd.concat([train, val])\n",
    "data = data.set_index('id')\n",
    "\n",
    "song_dic = data['songs'].to_dict()\n",
    "tag_dic = data['tags'].to_dict()\n",
    "data['song_name_token'] = data['songs'].progress_apply(lambda songs : sum([preprocess_string(song_meta.loc[song_id, 'song_name']) for song_id in songs], []))\n",
    "song_name_dic = data['song_name_token'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 138086/138086 [00:28<00:00, 4852.95it/s]\n"
     ]
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "total = data.progress_apply(lambda x : song_name_dic[x['id']] + tag_dic[x['id']] + preprocess_string(x['plylst_title']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(total, min_count = min_count, size = size, window = windows, sg = sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "138086it [09:14, 249.09it/s]\n"
     ]
    }
   ],
   "source": [
    "ID = []   \n",
    "vec = []\n",
    "embedd = {}\n",
    "for index, q in tqdm(pd.concat([train, val]).iterrows()):\n",
    "    tmp_vec = 0\n",
    "    for song_word in song_name_dic[q['id']]:\n",
    "        try:\n",
    "            tmp_vec += w2v_model.wv.get_vector(song_word) / len(song_name_dic[q['id']])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    for tag in tag_dic[q['id']]:\n",
    "        try:\n",
    "            tmp_vec += w2v_model.wv.get_vector(tag) / len(tag_dic[q['id']])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    for title_word in preprocess_string(q['plylst_title']):\n",
    "        try:\n",
    "            tmp_vec += 2 * w2v_model.wv.get_vector(title_word) / len(preprocess_string(q['plylst_title']))\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    if type(tmp_vec) != int:\n",
    "        embedd[str(q['id'])] = tmp_vec\n",
    "        ID.append(str(q['id']))  \n",
    "        vec.append(tmp_vec)\n",
    "\n",
    "p2v_model.add(ID, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23015it [09:29, 40.38it/s]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for index, q in tqdm(val.iterrows()):\n",
    "    try:\n",
    "        most_id = [x[0] for x in p2v_model.most_similar(str(q['id']), topn=200)]\n",
    "        get_song = []\n",
    "        get_tag = []\n",
    "        for ID in most_id:\n",
    "            get_song += song_dic[int(ID)]\n",
    "            get_tag += tag_dic[int(ID)]\n",
    "        get_song = list(pd.value_counts(get_song)[:200].index)\n",
    "        get_tag = list(pd.value_counts(get_tag)[:20].index)\n",
    "        answers.append({\n",
    "            \"id\": q[\"id\"],\n",
    "            \"songs\": remove_seen(q[\"songs\"], get_song)[:100],\n",
    "            \"tags\": remove_seen(q[\"tags\"], get_tag)[:10],\n",
    "        })\n",
    "    except:\n",
    "        answers.append({\n",
    "          \"id\": most_results.loc[index][\"id\"],\n",
    "          \"songs\": most_results.loc[index]['songs'],\n",
    "          \"tags\": most_results.loc[index][\"tags\"],\n",
    "        }) \n",
    "\n",
    "# check and update answer\n",
    "for n, q in enumerate(answers):\n",
    "    if len(q['songs'])!=100:\n",
    "        answers[n]['songs'] += remove_seen(q['songs'], most_results.loc[n]['songs'])[:100-len(q['songs'])]\n",
    "    if len(q['tags'])!=10:\n",
    "        answers[n]['tags'] += remove_seen(q['tags'], most_results.loc[n]['tags'])[:10-len(q['tags'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(answers, \"results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class로 만든 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표 : 플레이리스트(노래, 태그, 플레이리스트 제목)이 주어지면, K개의 feature를 뽑도록 한다.\n",
    "# 자연어 처리 모델을 구축\n",
    "class PlaylistEmbedding:\n",
    "    def __init__(self):\n",
    "        # 파일에서 긁어온다.\n",
    "        # 긁어올 파일 : train, val, song_meta\n",
    "        self.train = pd.read_json('./data/train.json', encoding='UTF-8')\n",
    "        self.val = pd.read_json('./data/val.json', encoding='UTF-8')\n",
    "        self.song_meta = pd.read_json('./data/song_meta.json', encoding='UTF-8')\n",
    "        self.most_results = pd.read_json('results.json', encoding='UTF-8')\n",
    "        self.min_count = 10\n",
    "        self.size = 100\n",
    "        self.windows = 100\n",
    "        self.sg = 1\n",
    "        self.p2v_model = WordEmbeddingsKeyedVectors(self.size)\n",
    "    \n",
    "    #플레이리스트 : (플레이리스트 제목과 모든 송의 제목을 gensim으로 preprocess, 장르도 우겨넣자) \n",
    "    def get_dic(self, train, val, song_meta):\n",
    "        song_dic = {} # plylst id - song id\n",
    "        song_name_dic = {} # plylst id - [preprocessed song name]\n",
    "        tag_dic = {} # plylst id - tag\n",
    "        data = pd.concat([train, val])\n",
    "        data = data.set_index('id')\n",
    "        \n",
    "        song_dic = data['songs'].to_dict()\n",
    "        tag_dic = data['tags'].to_dict()\n",
    "        data['song_name_token'] = data['songs'].map(lambda x : sum(list(map(lambda xx : preprocess_string(song_meta.loc[xx, 'song_name']), x)), []))\n",
    "        song_name_dic = data['song_name_token'].to_dict()\n",
    "        \n",
    "        '''\n",
    "        for index, q in tqdm(data.iterrows()):\n",
    "            song_name_dic[str(q['id'])] = sum(list(map(lambda x : preprocess_string(song_meta.loc[x]['song_name']), q['songs'])),[])\n",
    "            song_dic[str(q['id'])] = q['songs']\n",
    "            tag_dic[str(q['id'])] = q['tags']\n",
    "        '''\n",
    "        self.song_dic = song_dic\n",
    "        self.song_name_dic = song_name_dic\n",
    "        self.tag_dic = tag_dic\n",
    "        \n",
    "        data = data.reset_index()\n",
    "        total = data.apply(lambda x : song_name_dic[x['id']] + tag_dic[x['id']] + preprocess_string(x['plylst_title']), axis = 1)\n",
    "        # total = [x for x in total if len(x)>1]\n",
    "        self.total = total\n",
    "    \n",
    "    # word2vec 모델\n",
    "    def get_w2v(self):\n",
    "        w2v_model = Word2Vec(self.total, min_count = self.min_count, size = self.size, window = self.windows, sg = self.sg)\n",
    "        self.w2v_model = w2v_model\n",
    "    \n",
    "    # word2vec을 적합하고 embedded vector를 return\n",
    "    def update_p2v(self, train, val,w2v_model):\n",
    "        ID = []   \n",
    "        vec = []\n",
    "        embedd = {}\n",
    "        for index, q in tqdm(pd.concat([train, val]).iterrows()):\n",
    "            tmp_vec = 0\n",
    "            for song_word in self.song_name_dic[str(q['id'])]:\n",
    "                try:\n",
    "                    tmp_vec += w2v_model.wv.get_vector(song_word)\n",
    "                except KeyError:\n",
    "                        pass\n",
    "            for tag in self.tag_dic[str(q['id'])]:\n",
    "                try:\n",
    "                    tmp_vec += w2v_model.wv.get_vector(tag)\n",
    "                except KeyError:\n",
    "                        pass\n",
    "            for title_word in preprocess_string(q['plylst_title']):\n",
    "                #print(q['plylst_title'])\n",
    "                try:\n",
    "                    tmp_vec += w2v_model.wv.get_vector(title_word)\n",
    "                except KeyError:\n",
    "                        pass\n",
    "                    \n",
    "            if type(tmp_vec) != int:\n",
    "                embedd[str(q['id'])] = tmp_vec\n",
    "                ID.append(str(q['id']))    \n",
    "                vec.append(tmp_vec)\n",
    "                \n",
    "        self.embedd = embedd\n",
    "        self.p2v_model.add(ID, vec)\n",
    "        return embedd\n",
    "    \n",
    "    def get_results(self):\n",
    "        answers = []\n",
    "        for index, q in tqdm(self.val.iterrows()):\n",
    "            try:\n",
    "                most_id = [x[0] for x in self.p2v_model.most_similar(str(q['id']), topn=200)]\n",
    "                get_song = []\n",
    "                get_tag = []\n",
    "                for ID in most_id:\n",
    "                    get_song += self.song_dic[int(ID)]\n",
    "                    get_tag += self.tag_dic[int(ID)]\n",
    "                get_song = list(pd.value_counts(get_song)[:200].index)\n",
    "                get_tag = list(pd.value_counts(get_tag)[:20].index)\n",
    "                answers.append({\n",
    "                    \"id\": q[\"id\"],\n",
    "                    \"songs\": remove_seen(q[\"songs\"], get_song)[:100],\n",
    "                    \"tags\": remove_seen(q[\"tags\"], get_tag)[:10],\n",
    "                })\n",
    "            except:\n",
    "                answers.append({\n",
    "                  \"id\": self.most_results.loc[index][\"id\"],\n",
    "                  \"songs\": self.most_results.loc[index]['songs'],\n",
    "                  \"tags\": self.most_results.loc[index][\"tags\"],\n",
    "                }) \n",
    "                \n",
    "        # check and update answer\n",
    "        for n, q in enumerate(answers):\n",
    "            if len(q['songs'])!=100:\n",
    "                answers[n]['songs'] += remove_seen(q['songs'], self.most_results.loc[n]['songs'])[:100-len(q['songs'])]\n",
    "            if len(q['tags'])!=10:\n",
    "                answers[n]['tags'] += remove_seen(q['tags'], self.most_results.loc[n]['tags'])[:10-len(q['tags'])]  \n",
    "        self.answers = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist = PlaylistEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist.get_dic(playlist.train, playlist.val, playlist.song_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist.get_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist.update_p2v(playlist.train, playlist.val, playlist.w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(playlist.answers, \"results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
