{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%python is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%python most_popular.py run --train_fname=data/train.json --question_fname=data/val.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/66/04faeedb98bfa5f241d0399d0102456886179cabac0355475f23a2978847/gensim-3.8.3-cp37-cp37m-win_amd64.whl (24.2MB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/8e/464b06f5efd26f2dc16ce7bd1662c2f31cadf9104fdbcbf5994674cc3a51/smart_open-2.1.0.tar.gz (116kB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from gensim) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from gensim) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Collecting Cython==0.29.14 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/be/b14be5c3ad1ff73096b518be1538282f053ec34faaca60a8753d975d7e93/Cython-0.29.14-cp37-cp37m-win_amd64.whl (1.7MB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Collecting boto (from smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "Collecting boto3 (from smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/f4/41c1d8a69b07b2a087a7e552cbed21111ff36706fec2f1ba9983fba95771/boto3-1.14.20-py2.py3-none-any.whl (128kB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.6.16)\n",
      "Collecting botocore<1.18.0,>=1.17.20 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/a6/1710181d97a6763ccced7f69fff8beea751633af2a101c3d02826cf4acce/botocore-1.17.20-py2.py3-none-any.whl (6.3MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "Collecting docutils<0.16,>=0.10 (from botocore<1.18.0,>=1.17.20->boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from botocore<1.18.0,>=1.17.20->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\USER\\AppData\\Local\\pip\\Cache\\wheels\\25\\6c\\db\\7dcb26f19fb260c5629af85ed1c8ef9641143444fc7ec1fa08\n",
      "Successfully built smart-open\n",
      "Installing collected packages: boto, jmespath, docutils, botocore, s3transfer, boto3, smart-open, Cython, gensim\n",
      "Successfully installed Cython-0.29.14 boto-2.49.0 boto3-1.14.20 botocore-1.17.20 docutils-0.15.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "from gensim.parsing.preprocessing import preprocess_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표 : 플레이리스트(노래, 태그, 플레이리스트 제목)이 주어지면, K개의 feature를 뽑도록 한다.\n",
    "# 자연어 처리 모델을 구축\n",
    "class PlaylistEmbedding:\n",
    "    def __init__(self):\n",
    "        # 파일에서 긁어온다.\n",
    "        # 긁어올 파일 : train, val, song_meta\n",
    "        self.train = pd.read_json('./data/train.json', encoding='UTF-8')\n",
    "        self.val = pd.read_json('./data/val.json', encoding='UTF-8')\n",
    "        self.song_meta = pd.read_json('./data/song_meta.json', encoding='UTF-8')\n",
    "        self.most_results = pd.read_json('results.json', encoding='UTF-8')\n",
    "        self.min_count = 10\n",
    "        self.size = 100\n",
    "        self.windows = 100\n",
    "        self.sg = 1\n",
    "        self.p2v_model = WordEmbeddingsKeyedVectors(self.size)\n",
    "    \n",
    "    #플레이리스트 : (플레이리스트 제목과 모든 송의 제목을 gensim으로 preprocess, 장르도 우겨넣자) \n",
    "    def get_dic(self, train, val, song_meta):\n",
    "        song_dic = {} # plylst id - song id\n",
    "        song_name_dic = {} # plylst id - [preprocessed song name]\n",
    "        tag_dic = {} # plylst id - tag\n",
    "        data = pd.concat([train, val])\n",
    "        data = data.set_index('id')\n",
    "        \n",
    "        song_dic = data.to_dict('songs')\n",
    "        tag_dic = data.to_dict('tags')\n",
    "        data['song_name_token'] = data['songs'].map(lambda x : sum(list(map(lambda xx : preprocess_string(song_meta.loc[xx, 'song_name']), x)), []))\n",
    "        song_name_dic = data.to_dict('song_name_token')\n",
    "        \n",
    "        '''\n",
    "        for index, q in tqdm(data.iterrows()):\n",
    "            song_name_dic[str(q['id'])] = sum(list(map(lambda x : preprocess_string(song_meta.loc[x]['song_name']), q['songs'])),[])\n",
    "            song_dic[str(q['id'])] = q['songs']\n",
    "            tag_dic[str(q['id'])] = q['tags']\n",
    "        '''\n",
    "        self.song_dic = song_dic\n",
    "        self.song_name_dic = song_name_dic\n",
    "        self.tag_dic = tag_dic\n",
    "        total = data.apply(lambda x : song_name_dic[str(x['id'])] + tag_dic[str(x['id'])] + preprocess_string(x['plylst_title']), axis = 1)\n",
    "        # total = [x for x in total if len(x)>1]\n",
    "        self.total = total   \n",
    "    \n",
    "    # word2vec 모델\n",
    "    def get_w2v(self):\n",
    "        w2v_model = Word2Vec(self.total, min_count = self.min_count, size = self.size, window = self.windows, sg = self.sg)\n",
    "        self.w2v_model = w2v_model\n",
    "    \n",
    "    # word2vec을 적합하고 embedded vector를 return\n",
    "    def update_p2v(self, train, val,w2v_model):\n",
    "        ID = []   \n",
    "        vec = []\n",
    "        embedd = {}\n",
    "        for index, q in tqdm(pd.concat([train, val]).iterrows()):\n",
    "            tmp_vec = 0\n",
    "            for song_word in self.song_name_dic[str(q['id'])]:\n",
    "                try:\n",
    "                    tmp_vec += w2v_model.wv.get_vector(song_word)\n",
    "                except KeyError:\n",
    "                        pass\n",
    "            for tag in self.tag_dic[str(q['id'])]:\n",
    "                try:\n",
    "                    tmp_vec += w2v_model.wv.get_vector(tag)\n",
    "                except KeyError:\n",
    "                        pass\n",
    "            for title_word in preprocess_string(q['plylst_title']):\n",
    "                #print(q['plylst_title'])\n",
    "                try:\n",
    "                    tmp_vec += w2v_model.wv.get_vector(title_word)\n",
    "                except KeyError:\n",
    "                        pass\n",
    "                    \n",
    "            if type(tmp_vec) != int:\n",
    "                embedd[str(q['id'])] = tmp_vec\n",
    "                ID.append(str(q['id']))    \n",
    "                vec.append(tmp_vec)\n",
    "                \n",
    "        self.embedd = embedd\n",
    "        self.p2v_model.add(ID, vec)\n",
    "        return embedd\n",
    "    \n",
    "    def get_results(self):\n",
    "        answers = []\n",
    "        for index, q in tqdm(self.val.iterrows()):\n",
    "            try:\n",
    "                most_id = [x[0] for x in self.p2v_model.most_similar(str(q['id']), topn=200)]\n",
    "                get_song = []\n",
    "                get_tag = []\n",
    "                for ID in most_id:\n",
    "                    get_song += self.song_dic[ID]\n",
    "                    get_tag += self.tag_dic[ID]\n",
    "                get_song = list(pd.value_counts(get_song)[:200].index)\n",
    "                get_tag = list(pd.value_counts(get_tag)[:20].index)\n",
    "                answers.append({\n",
    "                    \"id\": q[\"id\"],\n",
    "                    \"songs\": remove_seen(q[\"songs\"], get_song)[:100],\n",
    "                    \"tags\": remove_seen(q[\"tags\"], get_tag)[:10],\n",
    "                })\n",
    "            except:\n",
    "                answers.append({\n",
    "                  \"id\": self.most_results.loc[index][\"id\"],\n",
    "                  \"songs\": self.most_results.loc[index]['songs'],\n",
    "                  \"tags\": self.most_results.loc[index][\"tags\"],\n",
    "                }) \n",
    "                \n",
    "        # check and update answer\n",
    "        for n, q in enumerate(answers):\n",
    "            if len(q['songs'])!=100:\n",
    "                answers[n]['songs'] += remove_seen(q['songs'], self.most_results.loc[n]['songs'])[:100-len(q['songs'])]\n",
    "            if len(q['tags'])!=10:\n",
    "                answers[n]['tags'] += remove_seen(q['tags'], self.most_results.loc[n]['tags'])[:10-len(q['tags'])]  \n",
    "        self.answers = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist = PlaylistEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             Feelings\n",
       "1    Bach : Partita No. 4 In D Major, BWV 828 - II....\n",
       "2                      Solsbury Hill (Remastered 2002)\n",
       "3    Feeling Right (Everything Is Nice) (Feat. Popc...\n",
       "4                                              그남자 그여자\n",
       "5                                  Para Los Enamorados\n",
       "6    Sibelius : Valse Triste Op.44 (시벨리우스 : 슬픈 왈츠 작...\n",
       "7    Superman March (From &#34;Superman&#34; / Live...\n",
       "8                        Lovers’ Leap (Feat. Qypthone)\n",
       "9                                         사랑, 그대라는 멜로디\n",
       "Name: song_name, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist.song_meta['song_name'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [hei, littl, girl, octagon, road, honeymoon, h...\n",
       "1     [한사람을, audit, timerock, 기다리다, 둘이서, 바보에게, 바보가, ...\n",
       "2     [도시의, alright, 좋아하니까, feat, amj, 그랬으면, feat, r...\n",
       "3     [unknown, frozen, soundtrack, version, duet, 이...\n",
       "4     [눈물에, 얼굴을, 묻는다, 학원별곡, 學園別曲, 떠나지마, doc와, blue, ...\n",
       "5     [attent, feat, justin, bieber, quavo, chanc, r...\n",
       "6     [feat, 서영은, half, moon, feat, 사랑하는, 사람에게, 고백하기...\n",
       "7     [여자는, 윤은혜, 샐러드송, 샐러드기념일, 상심증후군, feat, daylight...\n",
       "8     [별을따다, 사랑가, return, intro, 사랑가, rock, dead, ro...\n",
       "9     [anthem, triumph, heart, despair, strive, fate...\n",
       "10    [break, diva, hot, issu, 예삐오, abo, supa, dupa,...\n",
       "Name: songs, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist.train.loc[:10, 'songs'].map(lambda x : sum(list(map(lambda xx : preprocess_string(playlist.song_meta.loc[xx, 'song_name']), x)), []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78738it [55:54, 23.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bcfa5415ef86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplaylist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplaylist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaylist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaylist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msong_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplaylist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_w2v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplaylist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_p2v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplaylist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaylist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaylist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-1f604ee19c11>\u001b[0m in \u001b[0;36mget_dic\u001b[1;34m(self, train, val, song_meta)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0msong_name_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mpreprocess_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_meta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'song_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'songs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0msong_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'songs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mtag_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tags'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-1f604ee19c11>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0msong_name_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mpreprocess_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_meta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'song_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'songs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0msong_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'songs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mtag_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tags'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1911\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1912\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1913\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no slices here, handle elsewhere'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3608\u001b[0m             result = self._constructor_sliced(\n\u001b[0;32m   3609\u001b[0m                 \u001b[0mnew_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3610\u001b[1;33m                 name=self.index[loc], dtype=new_values.dtype)\n\u001b[0m\u001b[0;32m   3611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3612\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "playlist.get_dic(playlist.train, playlist.val, playlist.song_meta)\n",
    "playlist.get_w2v()\n",
    "playlist.update_p2v(playlist.train, playlist.val, playlist.w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23015it [04:39, 82.42it/s]\n"
     ]
    }
   ],
   "source": [
    "playlist.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = playlist.answers\n",
    "for index, row in enumerate(answers):\n",
    "    if(len(row['songs']) != 100):\n",
    "        answers[index]['songs']= list(set(row['songs'] + list(range(150 - len(row['songs'])))))[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(answers, \"wtf.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dosomething(song_name_dic, train, tag_dic, val,w2v_model, pllist):\n",
    "        ID = []   \n",
    "        vec = []\n",
    "        embedd = {}\n",
    "        for index, q in tqdm(pd.concat([train, val]).iterrows()):\n",
    "            tmp_vec = 0\n",
    "            for song_word in song_name_dic[str(q['id'])]:\n",
    "                try:\n",
    "                    tmp_vec += w2v_model.wv.get_vector(song_word)\n",
    "                except KeyError:\n",
    "                        pass\n",
    "            for tag in tag_dic[str(q['id'])]:\n",
    "                try:\n",
    "                    tmp_vec += w2v_model.wv.get_vector(tag)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            for title_word in preprocess_string(q['plylst_title']):\n",
    "                #print(q['plylst_title'])\n",
    "                try:\n",
    "                    tmp_vec += w2v_model.wv.get_vector(title_word)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if type(tmp_vec) != int:\n",
    "                embedd[str(q['id'])] = tmp_vec\n",
    "                ID.append(str(q['id']))    \n",
    "                vec.append(tmp_vec)\n",
    "                \n",
    "        pllist.embedd = embedd\n",
    "        pllist.p2v_model.add(ID, vec)\n",
    "        return embedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpresults(pllst, val, p2v_model, song_dic, tag_dic, most_results):\n",
    "        answers = []\n",
    "        for index, q in tqdm(val.iterrows()):\n",
    "            try:\n",
    "                most_id = [x[0] for x in p2v_model.most_similar(str(q['id']), topn=200)]\n",
    "                get_song = []\n",
    "                get_tag = []\n",
    "                for ID in most_id:\n",
    "                    get_song += song_dic[ID]\n",
    "                    get_tag += tag_dic[ID]\n",
    "                get_song = list(pd.value_counts(get_song)[:200].index)\n",
    "                get_tag = list(pd.value_counts(get_tag)[:20].index)\n",
    "                answers.append({\n",
    "                    \"id\": q[\"id\"],\n",
    "                    \"songs\": remove_seen(q[\"songs\"], get_song)[:100],\n",
    "                    \"tags\": remove_seen(q[\"tags\"], get_tag)[:10],\n",
    "                })\n",
    "            except:\n",
    "                answers.append({\n",
    "                  \"id\": most_results.loc[index][\"id\"],\n",
    "                  \"songs\": most_results.loc[index]['songs'],\n",
    "                  \"tags\": most_results.loc[index][\"tags\"],\n",
    "                })\n",
    "                \n",
    "        # check and update answer\n",
    "        for n, q in enumerate(answers):\n",
    "            if len(q['songs'])!=100:\n",
    "                answers[n]['songs'] += remove_seen(q['songs'], most_results.loc[n]['songs'])[:100-len(q['songs'])]\n",
    "            if len(q['tags'])!=10:\n",
    "                answers[n]['tags'] += remove_seen(q['tags'], most_results.loc[n]['tags'])[:10-len(q['tags'])]  \n",
    "        pllst.answers = answers\n",
    "        \n",
    "        return answers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
